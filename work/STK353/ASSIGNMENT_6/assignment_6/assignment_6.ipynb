{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment_6.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "heading",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# STK 353\n",
    "\n",
    "## Assignment 6: Machine Learning\n",
    "\n",
    "#### Internal examiner: Ineke Derks\n",
    "#### External examiner: Dr Sebnem Er\n",
    "\n",
    "### Total points: 35\n",
    "\n",
    "- Submission deadline: 23:00, Thursday 10 November 2021.\n",
    "- This assignment is individual work.\n",
    "- Some of the tests are hidden, and some are visible in order to guide you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Prepare the data\n",
    "\n",
    "The data can be found in 'IMDB.csv'. The IMDB dataset has 50K movie reviews, which can be used for natural language processing or text analytics. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. In this assignment, you are required to predict the number of positive and negative reviews using logistic regression and naive Bayes. Furthermore, you are required to determine the underlying topics using latent Dirichlet allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1.1 [1]\n",
    "\n",
    "- Read the data into a dataframe and call it 'review'.\n",
    "- **Important**: Make sure the dataset is saved in the **same** directory as your notebook.\n",
    "- Write the review column to a list. Only use the first 2500 rows. Call this list 'X_arr'.\n",
    "\n",
    "**Note**: Pay attention to the variable names specified. It is important that you keep to the names specified.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.1\n",
    "points: \n",
    "    each: 0.5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q_1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB.csv')\n",
    "review = pd.DataFrame(df)\n",
    "X_arr = review['review'].head(2500)\n",
    "X_arr = X_arr.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1.1 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1.2 [1]\n",
    "\n",
    "- Use sklearn.preprocessing LabelEncoder to encode the labels to binary values 0 or 1. Make a new column in the dataframe for this encoding and call it 'target'. Positive sentiment will be 1 and a negative sentiment will be 0.\n",
    "- Drop the sentiment column.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.2\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(review['sentiment'])\n",
    "target = le.transform(review['sentiment'])\n",
    "review['target'] = target\n",
    "review = review.drop(columns=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1.2 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie review sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q_2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2 -  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2.1 [3]\n",
    "\n",
    "- Use the sklearn TfidfVectorizer. Use the following parameters:\n",
    "    - stop_words = 'english'.\n",
    "    - token_pattern = r'\\b[^\\d\\W]+\\b'. \n",
    "- Call the instantiation 'tfidf'.\n",
    "- Get the vectorization (call it bag_of_words) and the feature names (call it 'feature_names_lr').\n",
    "- Write the vectorization to a dataframe with the feature_names as column headings. Call the dataframe 'vectorized_text_lr'.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.1\n",
    "points: \n",
    "    each: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q_3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        _  ___  ____  _____  \\\n",
      "0     0.0  0.0   0.0    0.0   \n",
      "1     0.0  0.0   0.0    0.0   \n",
      "2     0.0  0.0   0.0    0.0   \n",
      "3     0.0  0.0   0.0    0.0   \n",
      "4     0.0  0.0   0.0    0.0   \n",
      "...   ...  ...   ...    ...   \n",
      "2495  0.0  0.0   0.0    0.0   \n",
      "2496  0.0  0.0   0.0    0.0   \n",
      "2497  0.0  0.0   0.0    0.0   \n",
      "2498  0.0  0.0   0.0    0.0   \n",
      "2499  0.0  0.0   0.0    0.0   \n",
      "\n",
      "      ________________________________________________________________  \\\n",
      "0                                                   0.0                  \n",
      "1                                                   0.0                  \n",
      "2                                                   0.0                  \n",
      "3                                                   0.0                  \n",
      "4                                                   0.0                  \n",
      "...                                                 ...                  \n",
      "2495                                                0.0                  \n",
      "2496                                                0.0                  \n",
      "2497                                                0.0                  \n",
      "2498                                                0.0                  \n",
      "2499                                                0.0                  \n",
      "\n",
      "      __________________________________________________________________  \\\n",
      "0                                                   0.0                    \n",
      "1                                                   0.0                    \n",
      "2                                                   0.0                    \n",
      "3                                                   0.0                    \n",
      "4                                                   0.0                    \n",
      "...                                                 ...                    \n",
      "2495                                                0.0                    \n",
      "2496                                                0.0                    \n",
      "2497                                                0.0                    \n",
      "2498                                                0.0                    \n",
      "2499                                                0.0                    \n",
      "\n",
      "      ___is  _and_  _brooklyn_  _fargo_  ...  ángel  æon    è    é  élan  \\\n",
      "0       0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "1       0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "2       0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "3       0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "4       0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "...     ...    ...         ...      ...  ...    ...  ...  ...  ...   ...   \n",
      "2495    0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "2496    0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "2497    0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "2498    0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "2499    0.0    0.0         0.0      0.0  ...    0.0  0.0  0.0  0.0   0.0   \n",
      "\n",
      "      émigrés  être   ís  ísnt  île  \n",
      "0         0.0   0.0  0.0   0.0  0.0  \n",
      "1         0.0   0.0  0.0   0.0  0.0  \n",
      "2         0.0   0.0  0.0   0.0  0.0  \n",
      "3         0.0   0.0  0.0   0.0  0.0  \n",
      "4         0.0   0.0  0.0   0.0  0.0  \n",
      "...       ...   ...  ...   ...  ...  \n",
      "2495      0.0   0.0  0.0   0.0  0.0  \n",
      "2496      0.0   0.0  0.0   0.0  0.0  \n",
      "2497      0.0   0.0  0.0   0.0  0.0  \n",
      "2498      0.0   0.0  0.0   0.0  0.0  \n",
      "2499      0.0   0.0  0.0   0.0  0.0  \n",
      "\n",
      "[2500 rows x 27394 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern = r'\\b[^\\d\\W]+\\b',stop_words='english')\n",
    "bag_of_words = tfidf.fit_transform(X_arr)\n",
    "feature_names_lr = tfidf.get_feature_names()\n",
    "vectorized_text_lr = pd.DataFrame(bag_of_words.todense(),columns = feature_names_lr)\n",
    "print(vectorized_text_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.1 results: All test cases passed!"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q_4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Question 2.2 [1]\n",
    "\n",
    "Split the data into a training and test set.\n",
    "\n",
    "- Use a 70/30 split.\n",
    "- Use a seed of 27.\n",
    "- Name the training and test sets: X_train, Y_train, X_test, Y_test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.2\n",
    "points: \n",
    "    each: 0.5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q_4_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#  X_train, Y_train, X_test, Y_test\n",
    "train, test = train_test_split(vectorized_text_lr,test_size = 0.3, random_state= 27)\n",
    "X_train = train\n",
    "X_test = test\n",
    "Y_train = review['target'][train.index]\n",
    "Y_test = review['target'][test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.2 results: All test cases passed!"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2.3a [1]\n",
    "\n",
    "- Use the training set to check the class imbalance of the data set and call it 'class_ratio'.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.3a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ratio = Y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.3a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.3a results: All test cases passed!"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 2.3b [1]\n",
    "\n",
    "- In the markdown cell below, comment on the class ratio.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.3b\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class ratio is relatively 1:1, Which means the imbalance is minimal to non existant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 2.4  [1]\n",
    "\n",
    "Create an instance of the logistic regression model. Specify solver = 'lbfgs'.\n",
    "\n",
    "- Fit the model to the training data and call it 'logistic_model'. \n",
    "- Calculate the accuracy on the training data and call it 'log_acc'.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.4\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q_7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(solver = 'lbfgs', random_state = 27)\n",
    "logistic_model.fit(X_train,Y_train)\n",
    "\n",
    "predicted = logistic_model.predict(X_train)\n",
    "\n",
    "log_acc = metrics.accuracy_score(Y_train,predicted)\n",
    "print(log_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.4 results: All test cases passed!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2.5 [3]\n",
    "\n",
    "Predict class labels for the test set and calculate the class probabilities.\n",
    "\n",
    "- Call the predicted class labels 'predicted'.\n",
    "- Call the predicted class probabilities 'probs'.\n",
    "\n",
    "Calculate the following,\n",
    "\n",
    "- Calculate the accuracy score on the test set and call it 'log_acc_score'.\n",
    "- Calculate the precision score on the test set and call it 'log_prec_score'.\n",
    "- Calculate the recall score on the test set and call it 'log_rec_score'.\n",
    "- Calculate the auc (area under the curve) score on the test set and call it 'log_auc_score'.\n",
    "\n",
    "**Note**: Round the 'log_acc_score', 'log_prec_score', 'log_rec_score', and 'log_auc_score' values to 4 decimal points.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.5\n",
    "points: \n",
    "    each: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q_8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8349 0.8767 0.8074 0.8347\n"
     ]
    }
   ],
   "source": [
    "# predicted\n",
    "probs = logistic_model.predict_proba(X_test)\n",
    "predicted =  logistic_model.predict(X_test)\n",
    "log_acc_score = metrics.accuracy_score(Y_test,predicted)\n",
    "log_prec_score = metrics.precision_score(Y_test,predicted)\n",
    "log_rec_score = metrics.recall_score(Y_test,predicted)\n",
    "log_auc_score = metrics.roc_auc_score(Y_test,predicted)\n",
    "\n",
    "log_auc_score = round(log_auc_score,4)\n",
    "log_rec_score = round(log_rec_score,4)\n",
    "log_prec_score = round(log_prec_score,4)\n",
    "log_acc_score = round(log_acc_score,4)\n",
    "print(log_auc_score ,log_rec_score ,log_prec_score,log_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.5 results: All test cases passed!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "q_9_1",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 2.6 [1]\n",
    "\n",
    "Does the model perform better than randomly assigning classes? Explain why.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.6\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO, the accuracy score is below the score of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 2.7 [3]\n",
    "\n",
    "Draw the ROC curve.\n",
    "\n",
    "- Provide a title, x and y label.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.7\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = logistic_model.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "probs\n",
    "y_true = Y_test\n",
    "y_probas = probs\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_probas, pos_label=0)\n",
    "\n",
    "# Print ROC curve\n",
    "# plt.plot(fpr,tpr)\n",
    "# plt.show()\n",
    "\n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('ROC CURVE')\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 3 -  Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3.1 [3]\n",
    "\n",
    "- Use the sklearn Countvectorizer. Use the following parameters:\n",
    "    - stop_words = 'english'.\n",
    "    - token_pattern = r'\\b[^\\d\\W]+\\b'. \n",
    "- Call the instantiation 'matrix'.\n",
    "- Get the vectorization (call it bag_of_words) and the feature names (call it 'feature_names_nb').\n",
    "- Write the vectorization to a dataframe with the feature_names as column headings. Call the dataframe 'vectorized_text_nb'.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.1\n",
    "points: \n",
    "    each: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      _  ___  ____  _____  \\\n",
      "0     0    0     0      0   \n",
      "1     0    0     0      0   \n",
      "2     0    0     0      0   \n",
      "3     0    0     0      0   \n",
      "4     0    0     0      0   \n",
      "...  ..  ...   ...    ...   \n",
      "2495  0    0     0      0   \n",
      "2496  0    0     0      0   \n",
      "2497  0    0     0      0   \n",
      "2498  0    0     0      0   \n",
      "2499  0    0     0      0   \n",
      "\n",
      "      ________________________________________________________________  \\\n",
      "0                                                     0                  \n",
      "1                                                     0                  \n",
      "2                                                     0                  \n",
      "3                                                     0                  \n",
      "4                                                     0                  \n",
      "...                                                 ...                  \n",
      "2495                                                  0                  \n",
      "2496                                                  0                  \n",
      "2497                                                  0                  \n",
      "2498                                                  0                  \n",
      "2499                                                  0                  \n",
      "\n",
      "      __________________________________________________________________  \\\n",
      "0                                                     0                    \n",
      "1                                                     0                    \n",
      "2                                                     0                    \n",
      "3                                                     0                    \n",
      "4                                                     0                    \n",
      "...                                                 ...                    \n",
      "2495                                                  0                    \n",
      "2496                                                  0                    \n",
      "2497                                                  0                    \n",
      "2498                                                  0                    \n",
      "2499                                                  0                    \n",
      "\n",
      "      ___is  _and_  _brooklyn_  _fargo_  ...  ángel  æon  è  é  élan  émigrés  \\\n",
      "0         0      0           0        0  ...      0    0  0  0     0        0   \n",
      "1         0      0           0        0  ...      0    0  0  0     0        0   \n",
      "2         0      0           0        0  ...      0    0  0  0     0        0   \n",
      "3         0      0           0        0  ...      0    0  0  0     0        0   \n",
      "4         0      0           0        0  ...      0    0  0  0     0        0   \n",
      "...     ...    ...         ...      ...  ...    ...  ... .. ..   ...      ...   \n",
      "2495      0      0           0        0  ...      0    0  0  0     0        0   \n",
      "2496      0      0           0        0  ...      0    0  0  0     0        0   \n",
      "2497      0      0           0        0  ...      0    0  0  0     0        0   \n",
      "2498      0      0           0        0  ...      0    0  0  0     0        0   \n",
      "2499      0      0           0        0  ...      0    0  0  0     0        0   \n",
      "\n",
      "      être  ís  ísnt  île  \n",
      "0        0   0     0    0  \n",
      "1        0   0     0    0  \n",
      "2        0   0     0    0  \n",
      "3        0   0     0    0  \n",
      "4        0   0     0    0  \n",
      "...    ...  ..   ...  ...  \n",
      "2495     0   0     0    0  \n",
      "2496     0   0     0    0  \n",
      "2497     0   0     0    0  \n",
      "2498     0   0     0    0  \n",
      "2499     0   0     0    0  \n",
      "\n",
      "[2500 rows x 27394 columns]\n"
     ]
    }
   ],
   "source": [
    "matrix = CountVectorizer(token_pattern = r'\\b[^\\d\\W]+\\b',stop_words='english')\n",
    "bag_of_words = matrix.fit_transform(X_arr)\n",
    "feature_names_nb = matrix.get_feature_names()\n",
    "vectorized_text_nb = pd.DataFrame(bag_of_words.todense(),columns = feature_names_nb)\n",
    "print(vectorized_text_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3.1 results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3.2 [1]\n",
    "\n",
    "Split the data into a training and test set.\n",
    "\n",
    "- Use a 70/30 split.\n",
    "- Use a seed of 27.\n",
    "- Name the training and test sets: X_train, Y_train, X_test, Y_test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.2\n",
    "points: \n",
    "    each: 0.5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(vectorized_text_nb,test_size = 0.3, random_state= 27)\n",
    "X_train = train\n",
    "X_test = test\n",
    "Y_train = review['target'][train.index]\n",
    "Y_test = review['target'][test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3.3 [1]\n",
    "\n",
    "Create an instance of the Naive Bayes model.\n",
    "\n",
    "- Use MultinomialNB.\n",
    "- Fit the model to the training data and call it 'nb_model'. \n",
    "- Calculate the accuracy on the training data and call it 'nb_acc'.\n",
    "\n",
    "**Note**: Round the 'nb_acc' value to 4 decimal points.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.3\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb_model = nb.fit(X_train,Y_train)\n",
    "predicted = nb_model.predict(X_train)\n",
    "\n",
    "nb_acc = metrics.accuracy_score(Y_train,predicted)\n",
    "nb_acc = round(nb_acc,4)\n",
    "print(nb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3.3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3.3 results: All test cases passed!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3.4 [3]\n",
    "\n",
    "Predict class labels for the test set and calculate the class probabilities.\n",
    "\n",
    "- Call the predicted class labels 'predicted'.\n",
    "\n",
    "Calculate the following,\n",
    "\n",
    "- Calculate the accuracy score on the test set and call it 'nb_acc_score'.\n",
    "- Calculate the precision score on the test set and call it 'nb_prec_score'.\n",
    "- Calculate the recall score on the test set and call it 'nb_rec_score'.\n",
    "\n",
    "**Note**: Round the 'nb_acc_score', 'nb_prec_score' and 'nb_rec_score' values to 4 decimal points.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.4\n",
    "points: \n",
    "    each: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6032 0.9 0.7693\n"
     ]
    }
   ],
   "source": [
    "predicted =  logistic_model.predict(X_test)\n",
    "nb_acc_score = metrics.accuracy_score(Y_test,predicted)\n",
    "nb_prec_score = metrics.precision_score(Y_test,predicted)\n",
    "nb_rec_score = metrics.recall_score(Y_test,predicted)\n",
    "\n",
    "nb_rec_score = round(nb_rec_score,4)\n",
    "nb_prec_score = round(nb_prec_score,4)\n",
    "nb_acc_score = round(nb_acc_score,4)\n",
    "\n",
    "print(nb_rec_score ,nb_prec_score,nb_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 3.5 [3]\n",
    "\n",
    "Make use of the performance measures calculated and comment on the model performance.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.5\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model perfomance is poor in recall score, while it has high precision score of 90% and moderate accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4 [3]\n",
    "\n",
    "Which model do you recommend for classifying the IMDB review data? Give a motivation.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would recommend logistic regression, because model the model is consistent and has a good score for every performance measure, that was calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Movie review: Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 - Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 5.1 [1]\n",
    "\n",
    "- Use the sklearn Countvectorizer. Use the following parameters:\n",
    "    - stop_words = 'english'.\n",
    "    - max_features = 1000.\n",
    "    - token_pattern = r'\\b[^\\d\\W]+\\b'. \n",
    "- Call the instantiation 'lda_mat'.\n",
    "- Get the vectorization (call it bag_of_words) and the feature names (call it 'feature_names')\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.1\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_mat = CountVectorizer(token_pattern =r'\\b[^\\d\\W]+\\b', stop_words='english',max_features=1000)\n",
    "bag_of_words = lda_mat.fit_transform(X_arr)\n",
    "feature_names = lda_mat.get_feature_names()\n",
    "no_topics = 20\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components = no_topics,\n",
    "                                max_iter = 5,\n",
    "                                learning_method = 'online',\n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 0).fit(bag_of_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q5.1 results: All test cases passed!"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 5.2 [2]\n",
    "\n",
    "Write a function to find the top 15 unique words.\n",
    "\n",
    "- Function name: top_ten_features.\n",
    "\n",
    "    - Input: corpus (X_arr).\n",
    "    - Output: A list of tuples where the first tuple item is the word and the second tuple item is the frequency. Call this list 'top_ten'. \n",
    "\n",
    "**Note**: Use the same parameters as above for Countvectoriser.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.2\n",
    "points: \n",
    "    each: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ability', 1), ('able', 1), ('absolutely', 1), ('accent', 1), ('act', 1), ('acted', 1), ('acting', 1), ('action', 1), ('actor', 1), ('actors', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def top_ten_features(X_arr):\n",
    "    matrix = CountVectorizer(token_pattern =r'\\b[^\\d\\W]+\\b', stop_words='english',max_features=1000)\n",
    "    bag_of_words = matrix.fit_transform(X_arr)\n",
    "    feature_names = matrix.get_feature_names()\n",
    "    top_ten = Counter(feature_names)\n",
    "    top_ten = top_ten.most_common(10)\n",
    "    return top_ten\n",
    "\n",
    "top_ten = top_ten_features(X_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q5.2 results: All test cases passed!"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 5.3 [2]\n",
    "\n",
    "Call the function below to display the top ten words of each topic. As input, the function takes:\n",
    "\n",
    "- the fitted model.\n",
    "- the feature_names.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.5\n",
    "manual: true\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=5, n_components=20, random_state=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'accent',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'added',\n",
       " 'admit',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'adventure',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'air',\n",
       " 'alien',\n",
       " 'alive',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'american',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anne',\n",
       " 'annoying',\n",
       " 'anti',\n",
       " 'apart',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appears',\n",
       " 'aren',\n",
       " 'army',\n",
       " 'art',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'atmosphere',\n",
       " 'attempt',\n",
       " 'attempts',\n",
       " 'attention',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'b',\n",
       " 'baby',\n",
       " 'background',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'band',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'battle',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'ben',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'body',\n",
       " 'book',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'br',\n",
       " 'brain',\n",
       " 'break',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'budget',\n",
       " 'bunch',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'c',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'car',\n",
       " 'care',\n",
       " 'career',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'casting',\n",
       " 'cat',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'channel',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'cheesy',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chris',\n",
       " 'cinema',\n",
       " 'cinematography',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'cliché',\n",
       " 'climax',\n",
       " 'close',\n",
       " 'club',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'come',\n",
       " 'comedies',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'comic',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'computer',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'convincing',\n",
       " 'cool',\n",
       " 'cop',\n",
       " 'copy',\n",
       " 'couldn',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'crap',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'credit',\n",
       " 'credits',\n",
       " 'creepy',\n",
       " 'crew',\n",
       " 'crime',\n",
       " 'cult',\n",
       " 'culture',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'd',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decides',\n",
       " 'deep',\n",
       " 'definitely',\n",
       " 'delivers',\n",
       " 'depth',\n",
       " 'deserves',\n",
       " 'despite',\n",
       " 'details',\n",
       " 'development',\n",
       " 'dialog',\n",
       " 'dialogue',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'die',\n",
       " 'died',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'directed',\n",
       " 'directing',\n",
       " 'direction',\n",
       " 'director',\n",
       " 'directors',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disney',\n",
       " 'doctor',\n",
       " 'documentary',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dog',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'door',\n",
       " 'doubt',\n",
       " 'dr',\n",
       " 'drama',\n",
       " 'dramatic',\n",
       " 'dream',\n",
       " 'drive',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'dull',\n",
       " 'dumb',\n",
       " 'dvd',\n",
       " 'e',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'edge',\n",
       " 'editing',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'effort',\n",
       " 'elements',\n",
       " 'emotional',\n",
       " 'emotions',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'episode',\n",
       " 'episodes',\n",
       " 'era',\n",
       " 'escape',\n",
       " 'especially',\n",
       " 'event',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'evil',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'exciting',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'experience',\n",
       " 'explain',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'f',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'fairly',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'father',\n",
       " 'favorite',\n",
       " 'fear',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'festival',\n",
       " 'fi',\n",
       " 'fiction',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'filled',\n",
       " 'film',\n",
       " 'filmed',\n",
       " 'filmmakers',\n",
       " 'films',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'finds',\n",
       " 'fine',\n",
       " 'fit',\n",
       " 'flick',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'footage',\n",
       " 'forget',\n",
       " 'form',\n",
       " 'forward',\n",
       " 'free',\n",
       " 'french',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'g',\n",
       " 'game',\n",
       " 'garbage',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'general',\n",
       " 'genius',\n",
       " 'genre',\n",
       " 'george',\n",
       " 'german',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ghost',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'gore',\n",
       " 'got',\n",
       " 'grade',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'group',\n",
       " 'guess',\n",
       " 'gun',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hardly',\n",
       " 'hate',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heavy',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'henry',\n",
       " 'hero',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'holes',\n",
       " 'hollywood',\n",
       " 'home',\n",
       " 'honestly',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'horror',\n",
       " 'hospital',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'huge',\n",
       " 'human',\n",
       " 'humor',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'ideas',\n",
       " 'ii',\n",
       " 'imagine',\n",
       " 'imdb',\n",
       " 'immediately',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impression',\n",
       " 'including',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indian',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'intelligent',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'involved',\n",
       " 'island',\n",
       " 'isn',\n",
       " 'issues',\n",
       " 'italian',\n",
       " 'jack',\n",
       " 'james',\n",
       " 'japanese',\n",
       " 'jim',\n",
       " 'jimmy',\n",
       " 'job',\n",
       " 'john',\n",
       " 'joke',\n",
       " 'jokes',\n",
       " 'journey',\n",
       " 'just',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'kid',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killer',\n",
       " 'killing',\n",
       " 'kills',\n",
       " 'kind',\n",
       " 'king',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'la',\n",
       " 'lack',\n",
       " 'lady',\n",
       " 'lame',\n",
       " 'language',\n",
       " 'large',\n",
       " 'late',\n",
       " 'later',\n",
       " 'laugh',\n",
       " 'laughed',\n",
       " 'laughing',\n",
       " 'laughs',\n",
       " 'law',\n",
       " 'lead',\n",
       " 'leading',\n",
       " 'leads',\n",
       " 'learn',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'left',\n",
       " 'let',\n",
       " 'level',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'list',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'll',\n",
       " 'local',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'loud',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'low',\n",
       " 'm',\n",
       " 'mad',\n",
       " 'main',\n",
       " 'mainly',\n",
       " 'major',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'male',\n",
       " 'man',\n",
       " 'managed',\n",
       " 'manages',\n",
       " 'mark',\n",
       " 'married',\n",
       " 'masterpiece',\n",
       " 'match',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'meet',\n",
       " 'meets',\n",
       " 'members',\n",
       " 'memorable',\n",
       " 'men',\n",
       " 'mention',\n",
       " 'mentioned',\n",
       " 'mess',\n",
       " 'message',\n",
       " 'michael',\n",
       " 'middle',\n",
       " 'mind',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'moments',\n",
       " 'money',\n",
       " 'monster',\n",
       " 'mother',\n",
       " 'motion',\n",
       " 'moves',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'ms',\n",
       " 'murder',\n",
       " 'music',\n",
       " 'musical',\n",
       " 'mystery',\n",
       " 'named',\n",
       " 'names',\n",
       " 'narrative',\n",
       " 'nature',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'non',\n",
       " 'normal',\n",
       " 'note',\n",
       " 'novel',\n",
       " 'nudity',\n",
       " 'number',\n",
       " 'o',\n",
       " 'obvious',\n",
       " 'obviously',\n",
       " 'odd',\n",
       " 'office',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'older',\n",
       " 'ones',\n",
       " 'open',\n",
       " 'opening',\n",
       " 'opinion',\n",
       " 'order',\n",
       " 'original',\n",
       " 'oscar',\n",
       " 'outside',\n",
       " 'overall',\n",
       " 'pace',\n",
       " 'parents',\n",
       " 'park',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'parts',\n",
       " 'party',\n",
       " 'past',\n",
       " 'pathetic',\n",
       " 'paul',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'perfectly',\n",
       " 'performance',\n",
       " 'performances',\n",
       " 'period',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'peter',\n",
       " 'phone',\n",
       " 'photography',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'pieces',\n",
       " 'place',\n",
       " 'plain',\n",
       " 'planet',\n",
       " 'play',\n",
       " 'played',\n",
       " 'playing',\n",
       " 'plays',\n",
       " 'plenty',\n",
       " 'plot',\n",
       " 'plus',\n",
       " 'point',\n",
       " 'points',\n",
       " 'police',\n",
       " 'political',\n",
       " 'poor',\n",
       " 'poorly',\n",
       " 'popular',\n",
       " 'portrayal',\n",
       " 'portrayed',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'potential',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'predictable',\n",
       " 'premise',\n",
       " 'present',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'prison',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'produced',\n",
       " 'producers',\n",
       " 'production',\n",
       " 'project',\n",
       " 'public',\n",
       " 'pure',\n",
       " 'quality',\n",
       " 'question',\n",
       " 'quickly',\n",
       " 'quite',\n",
       " 'race',\n",
       " 'rare',\n",
       " 'rate',\n",
       " 'rated',\n",
       " 'rating',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'real',\n",
       " 'realistic',\n",
       " 'reality',\n",
       " 'realize',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'reasons',\n",
       " 'recently',\n",
       " 'recommend',\n",
       " 'recommended',\n",
       " 'red',\n",
       " 'relationship',\n",
       " 'release',\n",
       " 'released',\n",
       " 'remake',\n",
       " 'remember',\n",
       " 'rent',\n",
       " 'respect',\n",
       " 'rest',\n",
       " 'result',\n",
       " 'return',\n",
       " 'review',\n",
       " 'reviews',\n",
       " 'rich',\n",
       " 'richard',\n",
       " 'ridiculous',\n",
       " 'right',\n",
       " 'road',\n",
       " 'robert',\n",
       " 'rock',\n",
       " 'role',\n",
       " 'roles',\n",
       " 'romance',\n",
       " 'romantic',\n",
       " 'room',\n",
       " 'run',\n",
       " 'running',\n",
       " 'runs',\n",
       " 'ryan',\n",
       " 's',\n",
       " 'sad',\n",
       " 'sadly',\n",
       " 'said',\n",
       " 'save',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scary',\n",
       " 'scene',\n",
       " 'scenery',\n",
       " 'scenes',\n",
       " 'school',\n",
       " 'sci',\n",
       " 'science',\n",
       " 'score',\n",
       " 'scott',\n",
       " 'screen',\n",
       " 'screenplay',\n",
       " 'script',\n",
       " 'season',\n",
       " 'second',\n",
       " 'secret',\n",
       " 'seeing',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'sense',\n",
       " 'sequel',\n",
       " 'sequence',\n",
       " 'sequences',\n",
       " 'series',\n",
       " 'seriously',\n",
       " 'set',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'seven',\n",
       " 'sex',\n",
       " 'sexual',\n",
       " 'sexy',\n",
       " 'shame',\n",
       " 'shooting',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'shots',\n",
       " 'showing',\n",
       " 'shown',\n",
       " 'shows',\n",
       " 'silly',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'simply',\n",
       " 'singing',\n",
       " 'single',\n",
       " 'sister',\n",
       " 'sit',\n",
       " 'sitting',\n",
       " 'situation',\n",
       " 'situations',\n",
       " 'slightly',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smart',\n",
       " 'smith',\n",
       " 'social',\n",
       " 'society',\n",
       " 'solid',\n",
       " 'somewhat',\n",
       " 'son',\n",
       " 'song',\n",
       " 'songs',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'sort',\n",
       " 'sound',\n",
       " 'sounds',\n",
       " 'soundtrack',\n",
       " 'space',\n",
       " 'special',\n",
       " 'spent',\n",
       " 'spoilers',\n",
       " 'stage',\n",
       " 'stand',\n",
       " 'star',\n",
       " 'starring',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'started',\n",
       " 'starts',\n",
       " 'stay',\n",
       " 'steve',\n",
       " 'stop',\n",
       " 'store',\n",
       " 'stories',\n",
       " 'story',\n",
       " 'storyline',\n",
       " 'straight',\n",
       " 'strange',\n",
       " 'street',\n",
       " 'strong',\n",
       " 'studio',\n",
       " 'stuff',\n",
       " 'stupid',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subject',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'suddenly',\n",
       " 'super',\n",
       " 'superb',\n",
       " 'supporting',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surprisingly',\n",
       " 'suspense',\n",
       " 'sweet',\n",
       " 't',\n",
       " 'taken',\n",
       " 'takes',\n",
       " 'taking',\n",
       " 'tale',\n",
       " 'talent',\n",
       " 'talented',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'taste',\n",
       " 'team',\n",
       " 'television',\n",
       " 'tell',\n",
       " 'telling',\n",
       " 'tells',\n",
       " 'tension',\n",
       " 'terms',\n",
       " 'terrible',\n",
       " 'terrific',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'theater',\n",
       " 'theme',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'thinks',\n",
       " 'thought',\n",
       " 'thriller',\n",
       " 'thrown',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tired',\n",
       " 'title',\n",
       " 'today',\n",
       " 'told',\n",
       " 'tom',\n",
       " 'tony',\n",
       " 'took',\n",
       " 'total',\n",
       " 'totally',\n",
       " 'tough',\n",
       " 'town',\n",
       " 'tragic',\n",
       " 'train',\n",
       " 'trash',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'trip',\n",
       " 'trouble',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'truth',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'turned',\n",
       " 'turns',\n",
       " 'tv',\n",
       " 'twist',\n",
       " 'twists',\n",
       " 'type',\n",
       " 'typical',\n",
       " 'u',\n",
       " 'ultimately',\n",
       " 'understand',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'use',\n",
       " 'used',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usual',\n",
       " 'usually',\n",
       " 'utterly',\n",
       " 'value',\n",
       " 'van',\n",
       " 'various',\n",
       " 've',\n",
       " 'version',\n",
       " 'video',\n",
       " 'view',\n",
       " 'viewer',\n",
       " 'viewers',\n",
       " 'viewing',\n",
       " 'violence',\n",
       " 'violent',\n",
       " 'visual',\n",
       " 'voice',\n",
       " 'wait',\n",
       " 'waiting',\n",
       " 'walk',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wants',\n",
       " 'war',\n",
       " 'wasn',\n",
       " 'waste',\n",
       " 'wasted',\n",
       " 'watch',\n",
       " 'watched',\n",
       " 'watching',\n",
       " 'water',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'weak',\n",
       " 'week',\n",
       " 'weird',\n",
       " 'went',\n",
       " 'western',\n",
       " 'white',\n",
       " 'wife',\n",
       " 'william',\n",
       " 'win',\n",
       " 'wish',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'won',\n",
       " 'wonder',\n",
       " 'wonderful',\n",
       " 'word',\n",
       " 'words',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'works',\n",
       " 'world',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'worthy',\n",
       " 'wouldn',\n",
       " 'write',\n",
       " 'writer',\n",
       " 'writers',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'wrote',\n",
       " 'yeah',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yes',\n",
       " 'york',\n",
       " 'young',\n",
       " 'zombie']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_topics(model, feature_names):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "\n",
    "display(lda, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q1.2</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q2.3a</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q2.4</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q2.5</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q3.1</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q3.2</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q3.3</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q3.4</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q5.1</pre></strong> passed!</p>\n",
       "\n",
       "<p><strong><pre style='display: inline;'>q5.2</pre></strong> passed!</p>\n",
       "\n"
      ],
      "text/plain": [
       "q1.1 results: All test cases passed!\n",
       "\n",
       "q1.2 results: All test cases passed!\n",
       "\n",
       "q2.1 results: All test cases passed!\n",
       "\n",
       "q2.2 results: All test cases passed!\n",
       "\n",
       "q2.3a results: All test cases passed!\n",
       "\n",
       "q2.4 results: All test cases passed!\n",
       "\n",
       "q2.5 results: All test cases passed!\n",
       "\n",
       "q3.1 results: All test cases passed!\n",
       "\n",
       "q3.2 results: All test cases passed!\n",
       "\n",
       "q3.3 results: All test cases passed!\n",
       "\n",
       "q3.4 results: All test cases passed!\n",
       "\n",
       "q5.1 results: All test cases passed!\n",
       "\n",
       "q5.2 results: All test cases passed!\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <p>Your submission has been exported. Click <a href=\"assignment_6_2021_11_08T12_37_54_895722.zip\" target=\"_blank\">here</a>\n",
       "                to download the zip file.</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
